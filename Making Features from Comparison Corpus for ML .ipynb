{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\2918261\\\\Dropbox\\\\Corner Office Interviews'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('C://Users//2918261//Dropbox//Corner Office Interviews')\n",
    "# ('C://Users//Toshiba//Dropbox//Corner Office Interviews')\n",
    "# C://Users//2918261//Dropbox//Corner Office Interviews         \n",
    "# Toshiba//Dropbox//Corner Office Interviews')\n",
    "# ('C://Users//2918261//Courses//Oslo Summer School//notebooks//Interviews//Text')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "interviews = pd.read_json('C:/Users/2918261/Dropbox/Corner Office Interviews/ComparisonCorpusText/Json Tables for ML/interviews_full.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similar preprocessing from Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2918261\\AppData\\Local\\Continuum\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: cymem.cymem.Pool size changed, may indicate binary incompatibility. Expected 48 from C header, got 64 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\2918261\\AppData\\Local\\Continuum\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: cymem.cymem.Address size changed, may indicate binary incompatibility. Expected 24 from C header, got 40 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, nltk, spacy, gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = interviews.text.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [re.sub(\"\\'\", \"\", sent) for sent in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2918261\\AppData\\Local\\Continuum\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: cymem.cymem.Pool size changed, may indicate binary incompatibility. Expected 48 from C header, got 64 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\2918261\\AppData\\Local\\Continuum\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: cymem.cymem.Address size changed, may indicate binary incompatibility. Expected 24 from C header, got 40 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append(\" \".join([token.lemma_ if token.lemma_ not in ['-PRON-'] else '' for token in doc if token.pos_ in allowed_postags]))\n",
    "    return texts_out\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# Run in terminal: python3 -m spacy download en\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only Noun, Adj, Verb, Adverb\n",
    "data_lemmatized = lemmatization(data_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## looking specifically for 3 grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word',\n",
    "                             ngram_range = (3, 3),\n",
    "                             min_df = 10,                      # minimum reqd occurences of a word \n",
    "                             stop_words='english',             # remove stop words\n",
    "                             lowercase=True,                   # convert all words to lowercase\n",
    "                             token_pattern='[a-zA-Z0-9]{3,}',  # num chars > 3\n",
    "                             # max_features=50000,             # max number of uniq words\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vectorized = vectorizer.fit_transform(data_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsicity:  2.902957692229723 %\n"
     ]
    }
   ],
   "source": [
    "# Materialize the sparse data\n",
    "data_dense = data_vectorized.todense()\n",
    "\n",
    "# Compute Sparsicity = Percentage of Non-Zero cells\n",
    "print(\"Sparsicity: \", ((data_dense > 0).sum()/data_dense.size)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.DataFrame(data_dense,\n",
    "                 columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spend lot time             133\n",
       "want make sure              76\n",
       "new york city               69\n",
       "work really hard            50\n",
       "make sure people            45\n",
       "talk little bit             43\n",
       "think really important      40\n",
       "make good decision          36\n",
       "ask lot question            33\n",
       "need make sure              32\n",
       "think lot people            31\n",
       "make lot money              28\n",
       "tell little bit             28\n",
       "make people feel            27\n",
       "new york time               27\n",
       "make thing happen           27\n",
       "people really want          26\n",
       "work life balance           26\n",
       "make sure know              26\n",
       "want know want              24\n",
       "try make sure               24\n",
       "think important thing       24\n",
       "know know know              23\n",
       "work hour week              23\n",
       "just little bit             23\n",
       "high school college         23\n",
       "make sure everybody         22\n",
       "try new thing               22\n",
       "lot different thing         22\n",
       "chief operating officer     22\n",
       "                          ... \n",
       "open end question           11\n",
       "want know people            11\n",
       "think really good           11\n",
       "make lot sense              11\n",
       "think people want           11\n",
       "today year ago              11\n",
       "make sure work              11\n",
       "new business model          11\n",
       "tell people want            11\n",
       "people little bit           11\n",
       "say just want               11\n",
       "people say really           11\n",
       "just say know               11\n",
       "people tell story           11\n",
       "know know people            10\n",
       "people work company         10\n",
       "lot time people             10\n",
       "really want people          10\n",
       "say think say               10\n",
       "hire people really          10\n",
       "really really important     10\n",
       "thing tell people           10\n",
       "lot people just             10\n",
       "know lot people             10\n",
       "high school work            10\n",
       "thing little bit            10\n",
       "just want say               10\n",
       "make little bit             10\n",
       "people feel good            10\n",
       "just make decision          10\n",
       "Length: 189, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the same process with tfidf vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word',\n",
    "                             ngram_range = (3, 3),\n",
    "                             min_df = 10,                      # minimum reqd occurences of a word \n",
    "                             stop_words='english',             # remove stop words\n",
    "                             lowercase=True,                   # convert all words to lowercase\n",
    "                             token_pattern='[a-zA-Z0-9]{3,}',  # num chars > 3\n",
    "                             # max_features=50000,             # max number of uniq words\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tfidf_vectorized = tfidf_vectorizer.fit_transform(data_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsicity:  2.902957692229723 %\n"
     ]
    }
   ],
   "source": [
    "# Materialize the sparse data\n",
    "data_tfidf_dense = data_tfidf_vectorized.todense()\n",
    "\n",
    "# Compute Sparsicity = Percentage of Non-Zero cells\n",
    "print(\"Sparsicity: \", ((data_tfidf_dense > 0).sum()/data_tfidf_dense.size)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "threegrams = pd.DataFrame(data_tfidf_dense,\n",
    "                 columns=tfidf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "threegramscombined = pd.concat([interviews, threegrams], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## specifically looking for two grams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer_two = TfidfVectorizer(analyzer='word',\n",
    "                             ngram_range = (2, 2),\n",
    "                             min_df = 10,                      # minimum reqd occurences of a word \n",
    "                             stop_words='english',             # remove stop words\n",
    "                             lowercase=True,                   # convert all words to lowercase\n",
    "                             token_pattern='[a-zA-Z0-9]{3,}',  # num chars > 3\n",
    "                             # max_features=50000,             # max number of uniq words\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tfidf_vectorized_two = tfidf_vectorizer_two.fit_transform(data_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsicity:  4.326159121788859 %\n"
     ]
    }
   ],
   "source": [
    "# Materialize the sparse data\n",
    "data_tfidf_dense_two = data_tfidf_vectorized_two.todense()\n",
    "\n",
    "# Compute Sparsicity = Percentage of Non-Zero cells\n",
    "print(\"Sparsicity: \", ((data_tfidf_dense_two > 0).sum()/data_tfidf_dense_two.size)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "twograms = pd.DataFrame(data_tfidf_dense_two,\n",
    "                 columns=tfidf_vectorizer_two.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([threegramscombined, twograms], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now only words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer_one = TfidfVectorizer(analyzer='word',\n",
    "                             ngram_range = (1, 1),\n",
    "                             min_df = 10,                      # minimum reqd occurences of a word \n",
    "                             stop_words='english',             # remove stop words\n",
    "                             lowercase=True,                   # convert all words to lowercase\n",
    "                             token_pattern='[a-zA-Z0-9]{3,}',  # num chars > 3\n",
    "                             # max_features=50000,             # max number of uniq words\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tfidf_vectorized_one = tfidf_vectorizer_one.fit_transform(data_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsicity:  11.48197394322927 %\n"
     ]
    }
   ],
   "source": [
    "# Materialize the sparse data\n",
    "data_tfidf_dense_one = data_tfidf_vectorized_one.todense()\n",
    "\n",
    "# Compute Sparsicity = Percentage of Non-Zero cells\n",
    "print(\"Sparsicity: \", ((data_tfidf_dense_one > 0).sum()/data_tfidf_dense_one.size)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.DataFrame(data_tfidf_dense_one,\n",
    "                 columns=tfidf_vectorizer_one.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([combined, words], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Current Age</th>\n",
       "      <th>NativeSpeaker</th>\n",
       "      <th>Traded</th>\n",
       "      <th>MBA</th>\n",
       "      <th>Sector_Grouped</th>\n",
       "      <th>...</th>\n",
       "      <th>yell</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yield</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AaronBellCombined.txt</td>\n",
       "      <td>Very well. Thanks for having me.\\nYeah. So a little bit about adroll. First of all we were founded in 2007 uh with a...</td>\n",
       "      <td>AaronBell</td>\n",
       "      <td>M</td>\n",
       "      <td>AdRoll</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017125</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 8910 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                filename  \\\n",
       "0  AaronBellCombined.txt   \n",
       "\n",
       "                                                                                                                      text  \\\n",
       "0  Very well. Thanks for having me.\\nYeah. So a little bit about adroll. First of all we were founded in 2007 uh with a...   \n",
       "\n",
       "        Name  Gender Organization  Current Age  NativeSpeaker  Traded  MBA  \\\n",
       "0  AaronBell       M       AdRoll           42              1       0    0   \n",
       "\n",
       "   Sector_Grouped  ...   yell yellow  yesterday  yield      york  young  \\\n",
       "0               2  ...    0.0    0.0        0.0    0.0  0.013131    0.0   \n",
       "\n",
       "   youth  youtube      zone  zoom  \n",
       "0    0.0      0.0  0.017125   0.0  \n",
       "\n",
       "[1 rows x 8910 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Current Age</th>\n",
       "      <th>NativeSpeaker</th>\n",
       "      <th>Traded</th>\n",
       "      <th>MBA</th>\n",
       "      <th>Sector_Grouped</th>\n",
       "      <th>...</th>\n",
       "      <th>yell</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yield</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>WendyLeaCombined.txt</td>\n",
       "      <td>I  am running a startup catalyst publicprivate partnership that exists  to build a sustainable tech-based economy fo...</td>\n",
       "      <td>WendyLea</td>\n",
       "      <td>F</td>\n",
       "      <td>Get Satisfaction Inc</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014389</td>\n",
       "      <td>0.010037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>WillWrightCombined.txt</td>\n",
       "      <td>Basically its a game about life in the broadest possible sense. You start as a single-cell microbe at the beginning ...</td>\n",
       "      <td>WillWright</td>\n",
       "      <td>M</td>\n",
       "      <td>Maxis</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>WilliamDGreenCombined.txt</td>\n",
       "      <td>Were a very client-focused company. If you go back in our history we used to provide services but now we provide bus...</td>\n",
       "      <td>WilliamDGreen</td>\n",
       "      <td>M</td>\n",
       "      <td>Accenture LLP</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020139</td>\n",
       "      <td>0.029417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>YorgenEdholmCombined.txt</td>\n",
       "      <td>Founded in 1999 Palo Alto California-based Accellion has annual revenue closer to 50 million than 100 million and is...</td>\n",
       "      <td>YorgenEdholm</td>\n",
       "      <td>M</td>\n",
       "      <td>Accellion Inc</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>YuchunLeeCombined.txt</td>\n",
       "      <td>Allego is now in its sixth year and is cash flow positive so it was not about needing the funds. In fact I have turn...</td>\n",
       "      <td>YuchunLee</td>\n",
       "      <td>M</td>\n",
       "      <td>Allego</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026323</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052280</td>\n",
       "      <td>0.048623</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022726</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8910 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      filename  \\\n",
       "517       WendyLeaCombined.txt   \n",
       "518     WillWrightCombined.txt   \n",
       "519  WilliamDGreenCombined.txt   \n",
       "520   YorgenEdholmCombined.txt   \n",
       "521      YuchunLeeCombined.txt   \n",
       "\n",
       "                                                                                                                        text  \\\n",
       "517  I  am running a startup catalyst publicprivate partnership that exists  to build a sustainable tech-based economy fo...   \n",
       "518  Basically its a game about life in the broadest possible sense. You start as a single-cell microbe at the beginning ...   \n",
       "519  Were a very client-focused company. If you go back in our history we used to provide services but now we provide bus...   \n",
       "520  Founded in 1999 Palo Alto California-based Accellion has annual revenue closer to 50 million than 100 million and is...   \n",
       "521  Allego is now in its sixth year and is cash flow positive so it was not about needing the funds. In fact I have turn...   \n",
       "\n",
       "             Name  Gender          Organization  Current Age  NativeSpeaker  \\\n",
       "517       WendyLea      F  Get Satisfaction Inc           65              1   \n",
       "518     WillWright      M                 Maxis           59              1   \n",
       "519  WilliamDGreen      M         Accenture LLP           66              1   \n",
       "520   YorgenEdholm      M         Accellion Inc           64              0   \n",
       "521      YuchunLee      M                Allego           54              1   \n",
       "\n",
       "     Traded  MBA  Sector_Grouped  ...   yell    yellow  yesterday     yield  \\\n",
       "517       0    0               2  ...    0.0  0.000000   0.000000  0.000000   \n",
       "518       0    0               3  ...    0.0  0.047405   0.000000  0.000000   \n",
       "519       0    1               1  ...    0.0  0.000000   0.000000  0.020139   \n",
       "520       0    1               3  ...    0.0  0.000000   0.000000  0.000000   \n",
       "521       0    1               3  ...    0.0  0.000000   0.026323  0.000000   \n",
       "\n",
       "         york     young  youth  youtube      zone  zoom  \n",
       "517  0.014389  0.010037    0.0      0.0  0.000000   0.0  \n",
       "518  0.000000  0.000000    0.0      0.0  0.000000   0.0  \n",
       "519  0.029417  0.000000    0.0      0.0  0.000000   0.0  \n",
       "520  0.000000  0.000000    0.0      0.0  0.000000   0.0  \n",
       "521  0.052280  0.048623    0.0      0.0  0.022726   0.0  \n",
       "\n",
       "[5 rows x 8910 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now LIWC categories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIWC = pd.read_excel('C:/Users/2918261/Dropbox/Corner Office Interviews/ComparisonCorpusText/LIWC_Combined_Full.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Fortune</th>\n",
       "      <th>Position</th>\n",
       "      <th>Current Age</th>\n",
       "      <th>Higher Education Info</th>\n",
       "      <th>Birth Country</th>\n",
       "      <th>Stock Market Info</th>\n",
       "      <th>BachelorsMin</th>\n",
       "      <th>...</th>\n",
       "      <th>Exclam</th>\n",
       "      <th>Dash</th>\n",
       "      <th>Quote</th>\n",
       "      <th>Apostro</th>\n",
       "      <th>Parenth</th>\n",
       "      <th>OtherP</th>\n",
       "      <th>Female</th>\n",
       "      <th>Sector_Grouped_Dic</th>\n",
       "      <th>Femininity</th>\n",
       "      <th>Masculinity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AaronBell</td>\n",
       "      <td>M</td>\n",
       "      <td>AdRoll</td>\n",
       "      <td>1</td>\n",
       "      <td>CEO</td>\n",
       "      <td>42</td>\n",
       "      <td>BS</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Communications</td>\n",
       "      <td>64.47</td>\n",
       "      <td>38.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AaronLevie</td>\n",
       "      <td>M</td>\n",
       "      <td>Box Inc</td>\n",
       "      <td>1</td>\n",
       "      <td>CEO</td>\n",
       "      <td>33</td>\n",
       "      <td>College Dropout</td>\n",
       "      <td>USA</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Technology</td>\n",
       "      <td>63.35</td>\n",
       "      <td>37.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AbbeRaven</td>\n",
       "      <td>F</td>\n",
       "      <td>A&amp;E Television Networks LLC</td>\n",
       "      <td>1</td>\n",
       "      <td>Acting Chairman</td>\n",
       "      <td>66</td>\n",
       "      <td>BA MA Honorary Doctorate</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Communications</td>\n",
       "      <td>62.63</td>\n",
       "      <td>38.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AbeAnkumah</td>\n",
       "      <td>M</td>\n",
       "      <td>Nyansa</td>\n",
       "      <td>0</td>\n",
       "      <td>CEO</td>\n",
       "      <td>41</td>\n",
       "      <td>BS MBA</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Technology</td>\n",
       "      <td>65.51</td>\n",
       "      <td>38.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdamNash</td>\n",
       "      <td>M</td>\n",
       "      <td>Wealthfront</td>\n",
       "      <td>0</td>\n",
       "      <td>Former CEO and President</td>\n",
       "      <td>44</td>\n",
       "      <td>BA MA MBA</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>62.76</td>\n",
       "      <td>40.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name  Gender                 Organization  Fortune  \\\n",
       "0  AaronBell       M                       AdRoll        1   \n",
       "1  AaronLevie      M                      Box Inc        1   \n",
       "2   AbbeRaven      F  A&E Television Networks LLC        1   \n",
       "3  AbeAnkumah      M                       Nyansa        0   \n",
       "4    AdamNash      M                  Wealthfront        0   \n",
       "\n",
       "                  Position   Current Age      Higher Education Info  \\\n",
       "0                       CEO           42                        BS    \n",
       "1                      CEO            33            College Dropout   \n",
       "2          Acting Chairman            66  BA MA Honorary Doctorate    \n",
       "3                       CEO           41                     BS MBA   \n",
       "4  Former CEO and President           44                  BA MA MBA   \n",
       "\n",
       "  Birth Country Stock Market Info  BachelorsMin     ...       Exclam  Dash  \\\n",
       "0           USA               NaN             1     ...            0  0.14   \n",
       "1           USA              NYSE             0     ...            0  0.33   \n",
       "2           USA               NaN             1     ...            0  0.39   \n",
       "3         Ghana               NaN             1     ...            0  0.98   \n",
       "4           USA               NaN             1     ...            0  0.35   \n",
       "\n",
       "   Quote  Apostro  Parenth OtherP Female Sector_Grouped_Dic Femininity  \\\n",
       "0    0.0      0.0        0    0.0      0     Communications      64.47   \n",
       "1    0.0      0.0        0    0.0      0         Technology      63.35   \n",
       "2    0.0      0.0        0    0.0      1     Communications      62.63   \n",
       "3    0.0      0.0        0    0.0      0         Technology      65.51   \n",
       "4    0.0      0.0        0    0.0      0              Other      62.76   \n",
       "\n",
       "   Masculinity  \n",
       "0        38.83  \n",
       "1        37.73  \n",
       "2        38.94  \n",
       "3        38.98  \n",
       "4        40.87  \n",
       "\n",
       "[5 rows x 132 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIWC.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make all the column names upper case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIWC.columns = map(str.upper, LIWC.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NAME ',\n",
       " 'GENDER',\n",
       " 'ORGANIZATION',\n",
       " 'FORTUNE',\n",
       " 'POSITION ',\n",
       " 'CURRENT AGE',\n",
       " 'HIGHER EDUCATION INFO',\n",
       " 'BIRTH COUNTRY',\n",
       " 'STOCK MARKET INFO',\n",
       " 'BACHELORSMIN',\n",
       " 'NATIVESPEAKER',\n",
       " 'TRADED',\n",
       " 'MBA',\n",
       " 'TITLELENGTH',\n",
       " 'PODCAST',\n",
       " 'PODCAST_DATE',\n",
       " 'PODCAST_LINK',\n",
       " 'PODCAST_DETAILS',\n",
       " 'INTERVIEW_DATE',\n",
       " 'INTERVIEW',\n",
       " 'INTERVIEW_LINK',\n",
       " 'INTERVIEW_DETAILS',\n",
       " 'CAPTION_DATE',\n",
       " 'CAPTION',\n",
       " 'CAPTION_LINK',\n",
       " 'CAPTION_DETAILS',\n",
       " 'ESSAY_DATE',\n",
       " 'ESSAY_TITLE',\n",
       " 'ESSAY',\n",
       " 'ESSAY_LINK ',\n",
       " 'OTHER SOURCES_DATE',\n",
       " 'OTHER SOURCES ',\n",
       " 'OTHER SOURCES_LINK',\n",
       " 'OTHER SOURCES_DETAILS',\n",
       " 'SECTOR_GROUPED',\n",
       " 'WC',\n",
       " 'ANALYTIC',\n",
       " 'CLOUT',\n",
       " 'AUTHENTIC',\n",
       " 'TONE',\n",
       " 'WPS',\n",
       " 'SIXLTR',\n",
       " 'DIC',\n",
       " 'FUNCTION',\n",
       " 'PRONOUN',\n",
       " 'PPRON',\n",
       " 'I',\n",
       " 'WE',\n",
       " 'YOU',\n",
       " 'SHEHE',\n",
       " 'THEY',\n",
       " 'IPRON',\n",
       " 'ARTICLE',\n",
       " 'PREP',\n",
       " 'AUXVERB',\n",
       " 'ADVERB',\n",
       " 'CONJ',\n",
       " 'NEGATE',\n",
       " 'VERB',\n",
       " 'ADJ',\n",
       " 'COMPARE',\n",
       " 'INTERROG',\n",
       " 'NUMBER',\n",
       " 'QUANT',\n",
       " 'AFFECT',\n",
       " 'POSEMO',\n",
       " 'NEGEMO',\n",
       " 'ANX',\n",
       " 'ANGER',\n",
       " 'SAD',\n",
       " 'SOCIAL',\n",
       " 'FAMILY',\n",
       " 'FRIEND',\n",
       " 'FEMALE',\n",
       " 'MALE',\n",
       " 'COGPROC',\n",
       " 'INSIGHT',\n",
       " 'CAUSE',\n",
       " 'DISCREP',\n",
       " 'TENTAT',\n",
       " 'CERTAIN',\n",
       " 'DIFFER',\n",
       " 'PERCEPT',\n",
       " 'SEE',\n",
       " 'HEAR',\n",
       " 'FEEL',\n",
       " 'BIO',\n",
       " 'BODY',\n",
       " 'HEALTH',\n",
       " 'SEXUAL',\n",
       " 'INGEST',\n",
       " 'DRIVES',\n",
       " 'AFFILIATION',\n",
       " 'ACHIEVE',\n",
       " 'POWER',\n",
       " 'REWARD',\n",
       " 'RISK',\n",
       " 'FOCUSPAST',\n",
       " 'FOCUSPRESENT',\n",
       " 'FOCUSFUTURE',\n",
       " 'RELATIV',\n",
       " 'MOTION',\n",
       " 'SPACE',\n",
       " 'TIME',\n",
       " 'WORK',\n",
       " 'LEISURE',\n",
       " 'HOME',\n",
       " 'MONEY',\n",
       " 'RELIG',\n",
       " 'DEATH',\n",
       " 'INFORMAL',\n",
       " 'SWEAR',\n",
       " 'NETSPEAK',\n",
       " 'ASSENT',\n",
       " 'NONFLU',\n",
       " 'FILLER',\n",
       " 'ALLPUNC',\n",
       " 'PERIOD',\n",
       " 'COMMA',\n",
       " 'COLON',\n",
       " 'SEMIC',\n",
       " 'QMARK',\n",
       " 'EXCLAM',\n",
       " 'DASH',\n",
       " 'QUOTE',\n",
       " 'APOSTRO',\n",
       " 'PARENTH',\n",
       " 'OTHERP',\n",
       " 'FEMALE',\n",
       " 'SECTOR_GROUPED_DIC',\n",
       " 'FEMININITY',\n",
       " 'MASCULINITY']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(LIWC.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## drop the some of the columns to avoid duplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIWC = LIWC.drop(['GENDER','FORTUNE',\n",
    " 'POSITION ',\n",
    " 'CURRENT AGE',\n",
    " 'HIGHER EDUCATION INFO',\n",
    " 'BIRTH COUNTRY',\n",
    " 'STOCK MARKET INFO',\n",
    " 'BACHELORSMIN',\n",
    " 'NATIVESPEAKER',\n",
    " 'TRADED',\n",
    " 'MBA',\n",
    " 'TITLELENGTH',\n",
    " 'PODCAST',\n",
    " 'PODCAST_DATE',\n",
    " 'PODCAST_LINK',\n",
    " 'PODCAST_DETAILS',\n",
    " 'INTERVIEW_DATE',\n",
    " 'INTERVIEW',\n",
    " 'INTERVIEW_LINK',\n",
    " 'INTERVIEW_DETAILS',\n",
    " 'CAPTION_DATE',\n",
    " 'CAPTION',\n",
    " 'CAPTION_LINK',\n",
    " 'CAPTION_DETAILS',\n",
    " 'ESSAY_DATE',\n",
    " 'ESSAY_TITLE',\n",
    " 'ESSAY',\n",
    " 'ESSAY_LINK ',\n",
    " 'OTHER SOURCES_DATE',\n",
    " 'OTHER SOURCES ',\n",
    " 'OTHER SOURCES_LINK',\n",
    " 'OTHER SOURCES_DETAILS',\n",
    " 'SECTOR_GROUPED',\n",
    " 'WC',\n",
    " 'ANALYTIC',\n",
    " 'CLOUT',\n",
    " 'AUTHENTIC',\n",
    " 'TONE',\n",
    " 'WPS',\n",
    " 'SIXLTR',\n",
    " 'DIC',\n",
    " 'NETSPEAK',\n",
    " 'ASSENT',\n",
    " 'NONFLU',\n",
    " 'FILLER',\n",
    " 'ALLPUNC',\n",
    " 'PERIOD',\n",
    " 'COMMA',\n",
    " 'COLON',\n",
    " 'SEMIC',\n",
    " 'QMARK',\n",
    " 'EXCLAM',\n",
    " 'DASH',\n",
    " 'QUOTE',\n",
    " 'APOSTRO',\n",
    " 'PARENTH',\n",
    " 'OTHERP',\n",
    " 'FEMALE',\n",
    " 'SECTOR_GROUPED_DIC',\n",
    " 'FEMININITY',\n",
    " 'MASCULINITY'], axis = 1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([combined, LIWC], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>filename</th>\n",
       "      <th>NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AaronBell</td>\n",
       "      <td>AaronBellCombined.txt</td>\n",
       "      <td>AaronBell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AaronLevie</td>\n",
       "      <td>AaronLevieCombined.txt</td>\n",
       "      <td>AaronLevie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AbbeRaven</td>\n",
       "      <td>AbbeRavenCombined.txt</td>\n",
       "      <td>AbbeRaven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AbeAnkumah</td>\n",
       "      <td>AbeAnkumahCombined.txt</td>\n",
       "      <td>AbeAnkumah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdamNash</td>\n",
       "      <td>AdamNashCombined.txt</td>\n",
       "      <td>AdamNash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdiTatarko</td>\n",
       "      <td>AdiTatarkoCombined.txt</td>\n",
       "      <td>AdiTatarko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AileenLee</td>\n",
       "      <td>AileenLeeCombined.txt</td>\n",
       "      <td>AileenLee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AlanDabbiere</td>\n",
       "      <td>AlanDabbiereCombined.txt</td>\n",
       "      <td>AlanDabbiere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AlanRMulally</td>\n",
       "      <td>AlanRMulallyCombined.txt</td>\n",
       "      <td>AlanRMulally</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AlanTrefler</td>\n",
       "      <td>AlanTreflerCombined.txt</td>\n",
       "      <td>AlanTrefler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AlastairMitchell</td>\n",
       "      <td>AlastairMitchellCombined.txt</td>\n",
       "      <td>AlastairMitchell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AlexandraWilkis</td>\n",
       "      <td>AlexandraWilkisCombined.txt</td>\n",
       "      <td>AlexandraWilkis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AlexavonTobel</td>\n",
       "      <td>AlexavonTobelCombined.txt</td>\n",
       "      <td>AlexavonTobel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AmberGuild</td>\n",
       "      <td>AmberGuildCombined.txt</td>\n",
       "      <td>AmberGuild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AmitSingh</td>\n",
       "      <td>AmitSinghCombined.txt</td>\n",
       "      <td>AmitSingh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AmyAstley</td>\n",
       "      <td>AmyAstleyCombined.txt</td>\n",
       "      <td>AmyAstley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AmyErrett</td>\n",
       "      <td>AmyErrettCombined.txt</td>\n",
       "      <td>AmyErrett</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AmyGutmann</td>\n",
       "      <td>AmyGutmannCombined.txt</td>\n",
       "      <td>AmyGutmann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AmyPressman</td>\n",
       "      <td>AmyPressmanCombined.txt</td>\n",
       "      <td>AmyPressman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AmySchulman</td>\n",
       "      <td>AmySchulmanCombined.txt</td>\n",
       "      <td>AmySchulman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AndreDurand</td>\n",
       "      <td>AndreDurandCombined.txt</td>\n",
       "      <td>AndreDurand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>AndrewCosslett</td>\n",
       "      <td>AndrewCosslettCombined.txt</td>\n",
       "      <td>AndrewCosslett</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AndrewFilev</td>\n",
       "      <td>AndrewFilevCombined.txt</td>\n",
       "      <td>AndrewFilev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>AndrewMThompson</td>\n",
       "      <td>AndrewMThompsonCombined.txt</td>\n",
       "      <td>AndrewMThompson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>AndyBryant</td>\n",
       "      <td>AndyBryantCombined.txt</td>\n",
       "      <td>AndyBryant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>AndyLansing</td>\n",
       "      <td>AndyLansingCombined.txt</td>\n",
       "      <td>AndyLansing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>AndyMills</td>\n",
       "      <td>AndyMillsCombined.txt</td>\n",
       "      <td>AndyMills</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>AngieHicks</td>\n",
       "      <td>AngieHicksCombined.txt</td>\n",
       "      <td>AngieHicks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>AngusDavis</td>\n",
       "      <td>AngusDavisCombined.txt</td>\n",
       "      <td>AngusDavis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>AnnCairns</td>\n",
       "      <td>AnnCairnsCombined.txt</td>\n",
       "      <td>AnnCairns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>TigerTyagarajan</td>\n",
       "      <td>TigerTyagarajanCombined.txt</td>\n",
       "      <td>TigerTyagarajan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>TimBrown</td>\n",
       "      <td>TimBrownCombined.txt</td>\n",
       "      <td>TimBrown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>TimBucher</td>\n",
       "      <td>TimBucherCombined.txt</td>\n",
       "      <td>TimBucher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>TobiLutke</td>\n",
       "      <td>TobiLutkeCombined.txt</td>\n",
       "      <td>TobiLutke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>ToddRovak</td>\n",
       "      <td>ToddRovakCombined.txt</td>\n",
       "      <td>ToddRovak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>TomErickson</td>\n",
       "      <td>TomEricksonCombined.txt</td>\n",
       "      <td>TomErickson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>TomLeighton</td>\n",
       "      <td>TomLeightonCombined.txt</td>\n",
       "      <td>TomLeighton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>TonyHsieh</td>\n",
       "      <td>TonyHsiehCombined.txt</td>\n",
       "      <td>TonyHsieh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>TonyTjan</td>\n",
       "      <td>TonyTjanCombined.txt</td>\n",
       "      <td>TonyTjan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>TraceyMatura</td>\n",
       "      <td>TraceyMaturaCombined.txt</td>\n",
       "      <td>TraceyMatura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>TracyDolgin</td>\n",
       "      <td>TracyDolginCombined.txt</td>\n",
       "      <td>TracyDolgin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>TracyStreckenbach</td>\n",
       "      <td>TracyStreckenbachCombined.txt</td>\n",
       "      <td>TracyStreckenbach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>TriciaClarkeStone</td>\n",
       "      <td>TriciaClarkeStoneCombined.txt</td>\n",
       "      <td>TriciaClarkeStone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>ValDiFebo</td>\n",
       "      <td>ValDiFeboCombined.txt</td>\n",
       "      <td>ValDiFebo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>ValerieSmith</td>\n",
       "      <td>ValerieSmithCombined.txt</td>\n",
       "      <td>ValerieSmith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>VictorAllis</td>\n",
       "      <td>VictorAllisCombined.txt</td>\n",
       "      <td>VictorAllis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>VictorHo</td>\n",
       "      <td>VictorHoCombined.txt</td>\n",
       "      <td>VictorHo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>VictoriaRansom</td>\n",
       "      <td>VictoriaRansomCombined.txt</td>\n",
       "      <td>VictoriaRansom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>VineetNayar</td>\n",
       "      <td>VineetNayarCombined.txt</td>\n",
       "      <td>VineetNayar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>VivekGupta</td>\n",
       "      <td>VivekGuptaCombined.txt</td>\n",
       "      <td>VivekGupta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>VivianLee</td>\n",
       "      <td>VivianLeeCombined.txt</td>\n",
       "      <td>VivianLee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>WainKellum</td>\n",
       "      <td>WainKellumCombined.txt</td>\n",
       "      <td>WainKellum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>WaltBettinger</td>\n",
       "      <td>WaltBettingerCombined.txt</td>\n",
       "      <td>WaltBettinger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>WayneJackson</td>\n",
       "      <td>WayneJacksonCombined.txt</td>\n",
       "      <td>WayneJackson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>WendyKopp</td>\n",
       "      <td>WendyKoppCombined.txt</td>\n",
       "      <td>WendyKopp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>WendyLea</td>\n",
       "      <td>WendyLeaCombined.txt</td>\n",
       "      <td>WendyLea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>WillWright</td>\n",
       "      <td>WillWrightCombined.txt</td>\n",
       "      <td>WillWright</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>WilliamDGreen</td>\n",
       "      <td>WilliamDGreenCombined.txt</td>\n",
       "      <td>WilliamDGreen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>YorgenEdholm</td>\n",
       "      <td>YorgenEdholmCombined.txt</td>\n",
       "      <td>YorgenEdholm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>YuchunLee</td>\n",
       "      <td>YuchunLeeCombined.txt</td>\n",
       "      <td>YuchunLee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>522 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name                        filename              NAME \n",
       "0           AaronBell           AaronBellCombined.txt         AaronBell \n",
       "1           AaronLevie         AaronLevieCombined.txt         AaronLevie\n",
       "2            AbbeRaven          AbbeRavenCombined.txt          AbbeRaven\n",
       "3           AbeAnkumah         AbeAnkumahCombined.txt         AbeAnkumah\n",
       "4             AdamNash           AdamNashCombined.txt           AdamNash\n",
       "5           AdiTatarko         AdiTatarkoCombined.txt         AdiTatarko\n",
       "6            AileenLee          AileenLeeCombined.txt          AileenLee\n",
       "7         AlanDabbiere       AlanDabbiereCombined.txt       AlanDabbiere\n",
       "8         AlanRMulally       AlanRMulallyCombined.txt       AlanRMulally\n",
       "9          AlanTrefler        AlanTreflerCombined.txt        AlanTrefler\n",
       "10    AlastairMitchell   AlastairMitchellCombined.txt   AlastairMitchell\n",
       "11     AlexandraWilkis    AlexandraWilkisCombined.txt    AlexandraWilkis\n",
       "12       AlexavonTobel      AlexavonTobelCombined.txt      AlexavonTobel\n",
       "13          AmberGuild         AmberGuildCombined.txt         AmberGuild\n",
       "14           AmitSingh          AmitSinghCombined.txt          AmitSingh\n",
       "15           AmyAstley          AmyAstleyCombined.txt          AmyAstley\n",
       "16           AmyErrett          AmyErrettCombined.txt          AmyErrett\n",
       "17          AmyGutmann         AmyGutmannCombined.txt         AmyGutmann\n",
       "18         AmyPressman        AmyPressmanCombined.txt        AmyPressman\n",
       "19         AmySchulman        AmySchulmanCombined.txt        AmySchulman\n",
       "20         AndreDurand        AndreDurandCombined.txt        AndreDurand\n",
       "21      AndrewCosslett     AndrewCosslettCombined.txt     AndrewCosslett\n",
       "22         AndrewFilev        AndrewFilevCombined.txt        AndrewFilev\n",
       "23     AndrewMThompson    AndrewMThompsonCombined.txt    AndrewMThompson\n",
       "24          AndyBryant         AndyBryantCombined.txt         AndyBryant\n",
       "25         AndyLansing        AndyLansingCombined.txt        AndyLansing\n",
       "26           AndyMills          AndyMillsCombined.txt          AndyMills\n",
       "27          AngieHicks         AngieHicksCombined.txt         AngieHicks\n",
       "28          AngusDavis         AngusDavisCombined.txt         AngusDavis\n",
       "29           AnnCairns          AnnCairnsCombined.txt          AnnCairns\n",
       "..                 ...                            ...                ...\n",
       "492    TigerTyagarajan    TigerTyagarajanCombined.txt    TigerTyagarajan\n",
       "493          TimBrown            TimBrownCombined.txt          TimBrown \n",
       "494          TimBucher          TimBucherCombined.txt          TimBucher\n",
       "495          TobiLutke          TobiLutkeCombined.txt          TobiLutke\n",
       "496          ToddRovak          ToddRovakCombined.txt          ToddRovak\n",
       "497        TomErickson        TomEricksonCombined.txt        TomErickson\n",
       "498        TomLeighton        TomLeightonCombined.txt        TomLeighton\n",
       "499          TonyHsieh          TonyHsiehCombined.txt          TonyHsieh\n",
       "500           TonyTjan           TonyTjanCombined.txt           TonyTjan\n",
       "501       TraceyMatura       TraceyMaturaCombined.txt       TraceyMatura\n",
       "502        TracyDolgin        TracyDolginCombined.txt        TracyDolgin\n",
       "503  TracyStreckenbach  TracyStreckenbachCombined.txt  TracyStreckenbach\n",
       "504  TriciaClarkeStone  TriciaClarkeStoneCombined.txt  TriciaClarkeStone\n",
       "505          ValDiFebo          ValDiFeboCombined.txt          ValDiFebo\n",
       "506       ValerieSmith       ValerieSmithCombined.txt       ValerieSmith\n",
       "507        VictorAllis        VictorAllisCombined.txt        VictorAllis\n",
       "508           VictorHo           VictorHoCombined.txt           VictorHo\n",
       "509     VictoriaRansom     VictoriaRansomCombined.txt     VictoriaRansom\n",
       "510        VineetNayar        VineetNayarCombined.txt        VineetNayar\n",
       "511         VivekGupta         VivekGuptaCombined.txt         VivekGupta\n",
       "512          VivianLee          VivianLeeCombined.txt          VivianLee\n",
       "513         WainKellum         WainKellumCombined.txt         WainKellum\n",
       "514      WaltBettinger      WaltBettingerCombined.txt      WaltBettinger\n",
       "515       WayneJackson       WayneJacksonCombined.txt       WayneJackson\n",
       "516          WendyKopp          WendyKoppCombined.txt          WendyKopp\n",
       "517           WendyLea           WendyLeaCombined.txt           WendyLea\n",
       "518         WillWright         WillWrightCombined.txt         WillWright\n",
       "519      WilliamDGreen      WilliamDGreenCombined.txt      WilliamDGreen\n",
       "520       YorgenEdholm       YorgenEdholmCombined.txt       YorgenEdholm\n",
       "521          YuchunLee          YuchunLeeCombined.txt          YuchunLee\n",
       "\n",
       "[522 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined[['Name ', 'filename', 'NAME ']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['filename',\n",
       " 'text',\n",
       " 'Name ',\n",
       " 'Gender',\n",
       " 'Organization',\n",
       " 'Current Age',\n",
       " 'NativeSpeaker',\n",
       " 'Traded',\n",
       " 'MBA',\n",
       " 'Sector_Grouped',\n",
       " 'Female',\n",
       " 'Sector_Grouped_Dic',\n",
       " 'Femininity',\n",
       " 'Masculinity',\n",
       " 'ago year ago',\n",
       " 'ask lot question',\n",
       " 'ask people tell',\n",
       " 'ask right question',\n",
       " 'ask tell time',\n",
       " 'bad thing happen',\n",
       " 'big mistake make',\n",
       " 'build great company',\n",
       " 'challenge status quo',\n",
       " 'chief operating officer',\n",
       " 'come say know',\n",
       " 'come work day',\n",
       " 'company year ago',\n",
       " 'couple year ago',\n",
       " 'create environment people',\n",
       " 'decision make decision',\n",
       " 'different point view',\n",
       " 'good thing happen',\n",
       " 'graduate high school',\n",
       " 'grow small town',\n",
       " 'harvard business school',\n",
       " 'high school college',\n",
       " 'high school student',\n",
       " 'high school work',\n",
       " 'hire good people',\n",
       " 'hire people really',\n",
       " 'important make sure',\n",
       " 'important thing learn',\n",
       " 'job make sure',\n",
       " 'just little bit',\n",
       " 'just make decision',\n",
       " 'just make sure',\n",
       " 'just say know',\n",
       " 'just want know',\n",
       " 'just want say',\n",
       " 'know just know',\n",
       " 'know know know',\n",
       " 'know know people',\n",
       " 'know little bit',\n",
       " 'know lot people',\n",
       " 'know say know',\n",
       " 'know think know',\n",
       " 'know want know',\n",
       " 'know year ago',\n",
       " 'learn hard way',\n",
       " 'learn lot people',\n",
       " 'let just say',\n",
       " 'let people know',\n",
       " 'little bit different',\n",
       " 'little bit time',\n",
       " 'long period time',\n",
       " 'long time ago',\n",
       " 'look people want',\n",
       " 'lot different thing',\n",
       " 'lot people come',\n",
       " 'lot people just',\n",
       " 'lot people say',\n",
       " 'lot people think',\n",
       " 'lot people work',\n",
       " 'lot smart people',\n",
       " 'lot time people',\n",
       " 'make big difference',\n",
       " 'make decision base',\n",
       " 'make decision make',\n",
       " 'make decision think',\n",
       " 'make feel good',\n",
       " 'make good decision',\n",
       " 'make little bit',\n",
       " 'make lot money',\n",
       " 'make lot sense',\n",
       " 'make mistake make',\n",
       " 'make people feel',\n",
       " 'make right decision',\n",
       " 'make sure everybody',\n",
       " 'make sure good',\n",
       " 'make sure know',\n",
       " 'make sure people',\n",
       " 'make sure right',\n",
       " 'make sure understand',\n",
       " 'make sure work',\n",
       " 'make thing good',\n",
       " 'make thing happen',\n",
       " 'make tough decision',\n",
       " 'mistake make mistake',\n",
       " 'need make sure',\n",
       " 'new business model',\n",
       " 'new york city',\n",
       " 'new york time',\n",
       " 'open end question',\n",
       " 'people ask question',\n",
       " 'people come say',\n",
       " 'people come work',\n",
       " 'people feel comfortable',\n",
       " 'people feel good',\n",
       " 'people hire people',\n",
       " 'people just want',\n",
       " 'people know know',\n",
       " 'people little bit',\n",
       " 'people make decision',\n",
       " 'people make sure',\n",
       " 'people really good',\n",
       " 'people really want',\n",
       " 'people say know',\n",
       " 'people say really',\n",
       " 'people say say',\n",
       " 'people say want',\n",
       " 'people spend time',\n",
       " 'people tell story',\n",
       " 'people want hear',\n",
       " 'people want know',\n",
       " 'people want people',\n",
       " 'people want work',\n",
       " 'people work company',\n",
       " 'people work hard',\n",
       " 'people work really',\n",
       " 'probably important thing',\n",
       " 'question ask people',\n",
       " 'question ask tell',\n",
       " 'really good people',\n",
       " 'really good thing',\n",
       " 'really important thing',\n",
       " 'really important think',\n",
       " 'really look people',\n",
       " 'really make difference',\n",
       " 'really really good',\n",
       " 'really really hard',\n",
       " 'really really important',\n",
       " 'really smart people',\n",
       " 'really want know',\n",
       " 'really want people',\n",
       " 'really want work',\n",
       " 'right people right',\n",
       " 'say just want',\n",
       " 'say know know',\n",
       " 'say know really',\n",
       " 'say know say',\n",
       " 'say know think',\n",
       " 'say think say',\n",
       " 'school high school',\n",
       " 'short period time',\n",
       " 'smart person room',\n",
       " 'spend lot time',\n",
       " 'spend time people',\n",
       " 'spend time think',\n",
       " 'start year ago',\n",
       " 'talk little bit',\n",
       " 'tell little bit',\n",
       " 'tell people want',\n",
       " 'thing little bit',\n",
       " 'thing look people',\n",
       " 'thing really important',\n",
       " 'thing tell people',\n",
       " 'thing want people',\n",
       " 'think good job',\n",
       " 'think good thing',\n",
       " 'think good way',\n",
       " 'think important thing',\n",
       " 'think little bit',\n",
       " 'think lot people',\n",
       " 'think people want',\n",
       " 'think really good',\n",
       " 'think really important',\n",
       " 'think want hear',\n",
       " 'time make sure',\n",
       " 'today year ago',\n",
       " 'town hall meeting',\n",
       " 'try make sure',\n",
       " 'try new thing',\n",
       " 'wall street journal',\n",
       " 'want come work',\n",
       " 'want know people',\n",
       " 'want know think',\n",
       " 'want know want',\n",
       " 'want know work',\n",
       " 'want make sure',\n",
       " 'want people know',\n",
       " 'want spend time',\n",
       " 'want work company',\n",
       " 'work hard work',\n",
       " 'work hour day',\n",
       " 'work hour week',\n",
       " 'work life balance',\n",
       " 'work make sure',\n",
       " 'work really hard',\n",
       " 'year ago say',\n",
       " 'year ago start',\n",
       " 'year ago think',\n",
       " 'year ago year',\n",
       " 'year high school',\n",
       " 'ability listen',\n",
       " 'ability make',\n",
       " 'able bring',\n",
       " 'able build',\n",
       " 'able come',\n",
       " 'able deliver',\n",
       " 'able help',\n",
       " 'able just',\n",
       " 'able know',\n",
       " 'able learn',\n",
       " 'able look',\n",
       " 'able make',\n",
       " 'able people',\n",
       " 'able provide',\n",
       " 'able really',\n",
       " 'able say',\n",
       " 'able sell',\n",
       " 'able talk',\n",
       " 'able tell',\n",
       " 'able thing',\n",
       " 'able think',\n",
       " 'able use',\n",
       " 'able work',\n",
       " 'absolutely critical',\n",
       " 'absolutely love',\n",
       " 'absolutely think',\n",
       " 'access information',\n",
       " 'accomplish goal',\n",
       " 'achieve goal',\n",
       " 'acquire company',\n",
       " 'actually able',\n",
       " 'actually ask',\n",
       " 'actually build',\n",
       " 'actually change',\n",
       " 'actually come',\n",
       " 'actually create',\n",
       " 'actually end',\n",
       " 'actually good',\n",
       " 'actually great',\n",
       " 'actually happen',\n",
       " 'actually help',\n",
       " 'actually just',\n",
       " 'actually know',\n",
       " 'actually learn',\n",
       " 'actually like',\n",
       " 'actually look',\n",
       " 'actually lot',\n",
       " 'actually make',\n",
       " 'actually meet',\n",
       " 'actually need',\n",
       " 'actually people',\n",
       " 'actually pretty',\n",
       " 'actually quite',\n",
       " 'actually really',\n",
       " 'actually say',\n",
       " 'actually spend',\n",
       " 'actually start',\n",
       " 'actually talk',\n",
       " 'actually tell',\n",
       " 'actually think',\n",
       " 'actually time',\n",
       " 'actually try',\n",
       " 'actually turn',\n",
       " 'actually use',\n",
       " 'actually want',\n",
       " 'actually work',\n",
       " 'adapt change',\n",
       " 'add new',\n",
       " 'add value',\n",
       " 'advance career',\n",
       " 'advice people',\n",
       " 'afraid make',\n",
       " 'african american',\n",
       " 'ago just',\n",
       " 'ago know',\n",
       " 'ago say',\n",
       " 'ago start',\n",
       " 'ago think',\n",
       " 'ago year',\n",
       " 'ahead time',\n",
       " 'allow people',\n",
       " 'amazing people',\n",
       " 'amazing thing',\n",
       " 'amazing work',\n",
       " 'answer ask',\n",
       " 'answer just',\n",
       " 'answer know',\n",
       " 'answer people',\n",
       " 'answer question',\n",
       " 'answer really',\n",
       " 'answer say',\n",
       " 'answer think',\n",
       " 'answer want',\n",
       " 'anybody come',\n",
       " 'anybody know',\n",
       " 'anybody want',\n",
       " 'apply job',\n",
       " 'appreciate people',\n",
       " 'approach people',\n",
       " 'area business',\n",
       " 'area focus',\n",
       " 'area need',\n",
       " 'area people',\n",
       " 'area really',\n",
       " 'area think',\n",
       " 'art science',\n",
       " 'artificial intelligence',\n",
       " 'ask advice',\n",
       " 'ask ask',\n",
       " 'ask big',\n",
       " 'ask come',\n",
       " 'ask employee',\n",
       " 'ask experience',\n",
       " 'ask good',\n",
       " 'ask hard',\n",
       " 'ask help',\n",
       " 'ask job',\n",
       " 'ask just',\n",
       " 'ask know',\n",
       " 'ask leave',\n",
       " 'ask like',\n",
       " 'ask lot',\n",
       " 'ask make',\n",
       " 'ask need',\n",
       " 'ask people',\n",
       " 'ask question',\n",
       " 'ask really',\n",
       " 'ask right',\n",
       " 'ask say',\n",
       " 'ask somebody',\n",
       " 'ask talk',\n",
       " 'ask team',\n",
       " 'ask tell',\n",
       " 'ask thing',\n",
       " 'ask think',\n",
       " 'ask time',\n",
       " 'ask want',\n",
       " 'ask work',\n",
       " 'ask write',\n",
       " 'ask year',\n",
       " 'aspect business',\n",
       " 'aspect life',\n",
       " 'assume know',\n",
       " 'assume people',\n",
       " 'attract people',\n",
       " 'away just',\n",
       " 'away people',\n",
       " 'away think',\n",
       " 'awful lot',\n",
       " 'bad boss',\n",
       " 'bad day',\n",
       " 'bad decision',\n",
       " 'bad happen',\n",
       " 'bad idea',\n",
       " 'bad news',\n",
       " 'bad people',\n",
       " 'bad say',\n",
       " 'bad thing',\n",
       " 'bad time',\n",
       " 'balance sheet',\n",
       " 'bank account',\n",
       " 'basically just',\n",
       " 'basically say',\n",
       " 'basketball team',\n",
       " 'bay area',\n",
       " 'bear raise',\n",
       " 'believe believe',\n",
       " 'believe big',\n",
       " 'believe company',\n",
       " 'believe good',\n",
       " 'believe happen',\n",
       " 'believe just',\n",
       " 'believe know',\n",
       " 'believe make',\n",
       " 'believe people',\n",
       " 'believe really',\n",
       " 'believe right',\n",
       " 'believe strongly',\n",
       " 'believe thing',\n",
       " 'believe think',\n",
       " 'believe want',\n",
       " 'believe way',\n",
       " 'believe year',\n",
       " 'better good',\n",
       " 'better make',\n",
       " 'better think',\n",
       " 'better understand',\n",
       " 'big believer',\n",
       " 'big big',\n",
       " 'big business',\n",
       " 'big challenge',\n",
       " 'big change',\n",
       " 'big company',\n",
       " 'big corporation',\n",
       " 'big customer',\n",
       " 'big datum',\n",
       " 'big deal',\n",
       " 'big decision',\n",
       " 'big difference',\n",
       " 'big fan',\n",
       " 'big goal',\n",
       " 'big idea',\n",
       " 'big impact',\n",
       " 'big influence',\n",
       " 'big issue',\n",
       " 'big job',\n",
       " 'big just',\n",
       " 'big know',\n",
       " 'big lesson',\n",
       " 'big life',\n",
       " 'big mistake',\n",
       " 'big opportunity',\n",
       " 'big people',\n",
       " 'big picture',\n",
       " 'big piece',\n",
       " 'big problem',\n",
       " 'big project',\n",
       " 'big question',\n",
       " 'big risk',\n",
       " 'big role',\n",
       " 'big success',\n",
       " 'big thing',\n",
       " 'big think',\n",
       " 'big way',\n",
       " 'billion dollar',\n",
       " 'bit different',\n",
       " 'bit just',\n",
       " 'bit think',\n",
       " 'bit time',\n",
       " 'black white',\n",
       " 'board director',\n",
       " 'board know',\n",
       " 'board meeting',\n",
       " 'board member',\n",
       " 'board school',\n",
       " 'body language',\n",
       " 'book read',\n",
       " 'boss say',\n",
       " 'boss tell',\n",
       " 'boss want',\n",
       " 'brand brand',\n",
       " 'brand just',\n",
       " 'brand new',\n",
       " 'brand really',\n",
       " 'brand think',\n",
       " 'bring different',\n",
       " 'bring good',\n",
       " 'bring idea',\n",
       " 'bring new',\n",
       " 'bring organization',\n",
       " 'bring people',\n",
       " 'bring table',\n",
       " 'bring team',\n",
       " 'brother sister',\n",
       " 'build big',\n",
       " 'build brand',\n",
       " 'build build',\n",
       " 'build business',\n",
       " 'build company',\n",
       " 'build culture',\n",
       " 'build good',\n",
       " 'build great',\n",
       " 'build infrastructure',\n",
       " 'build just',\n",
       " 'build kind',\n",
       " 'build network',\n",
       " 'build new',\n",
       " 'build product',\n",
       " 'build relationship',\n",
       " 'build right',\n",
       " 'build software',\n",
       " 'build strong',\n",
       " 'build successful',\n",
       " 'build team',\n",
       " 'build thing',\n",
       " 'build trust',\n",
       " 'building team',\n",
       " 'bunch different',\n",
       " 'bunch people',\n",
       " 'bunch thing',\n",
       " 'business able',\n",
       " 'business actually',\n",
       " 'business big',\n",
       " 'business build',\n",
       " 'business business',\n",
       " 'business card',\n",
       " 'business change',\n",
       " 'business come',\n",
       " 'business community',\n",
       " 'business company',\n",
       " 'business create',\n",
       " 'business culture',\n",
       " 'business customer',\n",
       " 'business day',\n",
       " 'business decision',\n",
       " 'business development',\n",
       " 'business different',\n",
       " 'business environment',\n",
       " 'business feel',\n",
       " 'business good',\n",
       " 'business great',\n",
       " 'business grow',\n",
       " 'business hard',\n",
       " 'business idea',\n",
       " 'business just',\n",
       " 'business kind',\n",
       " 'business know',\n",
       " 'business leader',\n",
       " 'business learn',\n",
       " 'business look',\n",
       " 'business lot',\n",
       " 'business make',\n",
       " 'business management',\n",
       " 'business model',\n",
       " 'business need',\n",
       " 'business opportunity',\n",
       " 'business owner',\n",
       " 'business partner',\n",
       " 'business people',\n",
       " 'business plan',\n",
       " 'business process',\n",
       " 'business really',\n",
       " 'business right',\n",
       " 'business run',\n",
       " 'business say',\n",
       " 'business school',\n",
       " 'business start',\n",
       " 'business strategy',\n",
       " 'business tell',\n",
       " 'business thing',\n",
       " 'business think',\n",
       " 'business time',\n",
       " 'business today',\n",
       " 'business try',\n",
       " 'business unit',\n",
       " 'business use',\n",
       " 'business want',\n",
       " 'business way',\n",
       " 'business work',\n",
       " 'business world',\n",
       " 'business year',\n",
       " 'buy company',\n",
       " 'buy new',\n",
       " 'buy product',\n",
       " 'buy sell',\n",
       " 'care care',\n",
       " 'care deeply',\n",
       " 'care just',\n",
       " 'care kid',\n",
       " 'care know',\n",
       " 'care lot',\n",
       " 'care make',\n",
       " 'care people',\n",
       " 'care really',\n",
       " 'care think',\n",
       " 'career just',\n",
       " 'career know',\n",
       " 'career lot',\n",
       " 'career need',\n",
       " 'career path',\n",
       " 'career people',\n",
       " 'career really',\n",
       " 'career say',\n",
       " 'career tell',\n",
       " 'career thing',\n",
       " 'career think',\n",
       " 'career time',\n",
       " 'career want',\n",
       " 'career work',\n",
       " 'case people',\n",
       " 'case study',\n",
       " 'cash flow',\n",
       " 'cell phone',\n",
       " 'ceo company',\n",
       " 'ceo know',\n",
       " 'ceo say',\n",
       " 'ceo think',\n",
       " 'certain kind',\n",
       " 'certain level',\n",
       " 'certain people',\n",
       " 'certain point',\n",
       " 'certain thing',\n",
       " 'certain way',\n",
       " 'certainly know',\n",
       " 'challenge business',\n",
       " 'challenge face',\n",
       " 'challenge just',\n",
       " 'challenge know',\n",
       " 'challenge learn',\n",
       " 'challenge make',\n",
       " 'challenge people',\n",
       " 'challenge say',\n",
       " 'challenge status',\n",
       " 'challenge thing',\n",
       " 'challenge think',\n",
       " 'challenge want',\n",
       " 'chance make',\n",
       " 'chance work',\n",
       " 'change behavior',\n",
       " 'change big',\n",
       " 'change business',\n",
       " 'change change',\n",
       " 'change come',\n",
       " 'change company',\n",
       " 'change course',\n",
       " 'change culture',\n",
       " 'change dramatically',\n",
       " 'change environment',\n",
       " 'change fast',\n",
       " 'change happen',\n",
       " 'change industry',\n",
       " 'change job',\n",
       " 'change just',\n",
       " 'change know',\n",
       " 'change life',\n",
       " 'change lot',\n",
       " 'change make',\n",
       " 'change mind',\n",
       " 'change need',\n",
       " 'change people',\n",
       " 'change quickly',\n",
       " 'change thing',\n",
       " 'change think',\n",
       " 'change time',\n",
       " 'change want',\n",
       " 'change way',\n",
       " 'change world',\n",
       " 'change year',\n",
       " 'check box',\n",
       " 'chief executive',\n",
       " 'chief operating',\n",
       " 'child grow',\n",
       " 'child really',\n",
       " 'choice make',\n",
       " 'civil right',\n",
       " 'class president',\n",
       " 'clear path',\n",
       " 'clear vision',\n",
       " 'clear want',\n",
       " 'climate change',\n",
       " 'close door',\n",
       " 'cloud base',\n",
       " 'collect datum',\n",
       " 'college graduate',\n",
       " 'college just',\n",
       " 'college really',\n",
       " 'college say',\n",
       " 'college start',\n",
       " 'college student',\n",
       " 'college think',\n",
       " 'college work',\n",
       " 'college year',\n",
       " 'come actually',\n",
       " 'come answer',\n",
       " 'come ask',\n",
       " 'come big',\n",
       " 'come board',\n",
       " 'come business',\n",
       " 'come college',\n",
       " 'come come',\n",
       " 'come company',\n",
       " 'come conclusion',\n",
       " 'come day',\n",
       " 'come different',\n",
       " 'come end',\n",
       " 'come experience',\n",
       " 'come family',\n",
       " 'come good',\n",
       " 'come great',\n",
       " 'come help',\n",
       " 'come home',\n",
       " 'come idea',\n",
       " 'come interview',\n",
       " 'come job',\n",
       " 'come just',\n",
       " 'come kind',\n",
       " 'come know',\n",
       " 'come life',\n",
       " 'come little',\n",
       " 'come long',\n",
       " 'come look',\n",
       " 'come lot',\n",
       " 'come make',\n",
       " 'come meeting',\n",
       " 'come mind',\n",
       " 'come month',\n",
       " 'come naturally',\n",
       " 'come need',\n",
       " 'come new',\n",
       " 'come office',\n",
       " 'come organization',\n",
       " 'come outside',\n",
       " 'come people',\n",
       " 'come place',\n",
       " 'come play',\n",
       " 'come realize',\n",
       " 'come really',\n",
       " 'come right',\n",
       " 'come say',\n",
       " 'come second',\n",
       " 'come sit',\n",
       " 'come solution',\n",
       " 'come start',\n",
       " 'come talk',\n",
       " 'come tell',\n",
       " 'come thing',\n",
       " 'come think',\n",
       " 'come time',\n",
       " 'come try',\n",
       " 'come want',\n",
       " 'come way',\n",
       " 'come week',\n",
       " 'come work',\n",
       " 'come year',\n",
       " 'comfort zone',\n",
       " 'command control',\n",
       " 'common sense',\n",
       " 'communicate people',\n",
       " 'communication skill',\n",
       " 'community people',\n",
       " 'community work',\n",
       " 'company able',\n",
       " 'company acquire',\n",
       " 'company actually',\n",
       " 'company ask',\n",
       " 'company base',\n",
       " 'company believe',\n",
       " 'company better',\n",
       " 'company big',\n",
       " 'company board',\n",
       " 'company bring',\n",
       " 'company build',\n",
       " 'company business',\n",
       " 'company buy',\n",
       " 'company ceo',\n",
       " 'company change',\n",
       " 'company come',\n",
       " 'company company',\n",
       " 'company compete',\n",
       " 'company create',\n",
       " 'company culture',\n",
       " 'company customer',\n",
       " 'company day',\n",
       " 'company decide',\n",
       " 'company different',\n",
       " 'company early',\n",
       " 'company employee',\n",
       " 'company end',\n",
       " 'company especially',\n",
       " 'company everybody',\n",
       " 'company feel',\n",
       " 'company figure',\n",
       " 'company focus',\n",
       " 'company good',\n",
       " 'company great',\n",
       " 'company grow',\n",
       " 'company hard',\n",
       " 'company help',\n",
       " 'company hire',\n",
       " 'company idea',\n",
       " 'company important',\n",
       " 'company include',\n",
       " 'company industry',\n",
       " 'company invest',\n",
       " 'company just',\n",
       " 'company kind',\n",
       " 'company know',\n",
       " 'company large',\n",
       " 'company launch',\n",
       " 'company learn',\n",
       " 'company let',\n",
       " 'company little',\n",
       " 'company long',\n",
       " 'company look',\n",
       " 'company lot',\n",
       " 'company love',\n",
       " 'company make',\n",
       " 'company mean',\n",
       " 'company meeting',\n",
       " 'company month',\n",
       " 'company need',\n",
       " 'company new',\n",
       " 'company offer',\n",
       " 'company operate',\n",
       " 'company people',\n",
       " 'company probably',\n",
       " 'company product',\n",
       " 'company public',\n",
       " 'company question',\n",
       " 'company really',\n",
       " 'company reason',\n",
       " 'company right',\n",
       " 'company run',\n",
       " 'company sale',\n",
       " 'company say',\n",
       " 'company sell',\n",
       " 'company set',\n",
       " 'company share',\n",
       " 'company small',\n",
       " 'company sort',\n",
       " 'company spend',\n",
       " 'company start',\n",
       " 'company successful',\n",
       " 'company talk',\n",
       " 'company team',\n",
       " 'company tell',\n",
       " 'company tend',\n",
       " 'company thing',\n",
       " 'company think',\n",
       " 'company time',\n",
       " 'company today',\n",
       " 'company try',\n",
       " 'company turn',\n",
       " 'company understand',\n",
       " 'company use',\n",
       " 'company value',\n",
       " 'company walk',\n",
       " 'company want',\n",
       " 'company way',\n",
       " 'company work',\n",
       " 'company world',\n",
       " 'company year',\n",
       " 'companys success',\n",
       " 'competitive advantage',\n",
       " 'competitive environment',\n",
       " 'completely change',\n",
       " 'completely different',\n",
       " 'complex problem',\n",
       " 'computer science',\n",
       " 'conference room',\n",
       " 'connect customer',\n",
       " 'connect dot',\n",
       " 'connect people',\n",
       " 'constantly ask',\n",
       " 'constantly look',\n",
       " 'consult firm',\n",
       " 'consulting firm',\n",
       " 'consumer business',\n",
       " 'consumer product',\n",
       " 'consumer think',\n",
       " 'consumer want',\n",
       " 'continue build',\n",
       " 'continue grow',\n",
       " 'continue invest',\n",
       " 'continue make',\n",
       " 'continue work',\n",
       " 'control destiny',\n",
       " 'conventional wisdom',\n",
       " 'conversation happen',\n",
       " 'conversation people',\n",
       " 'conversation really',\n",
       " 'conversation think',\n",
       " 'convince people',\n",
       " 'cool stuff',\n",
       " 'cool thing',\n",
       " 'core business',\n",
       " 'core value',\n",
       " 'corporate america',\n",
       " 'corporate culture',\n",
       " 'corporate world',\n",
       " 'country think',\n",
       " 'country work',\n",
       " 'country world',\n",
       " 'couple day',\n",
       " 'couple different',\n",
       " 'couple hour',\n",
       " 'couple month',\n",
       " 'couple people',\n",
       " 'couple thing',\n",
       " 'couple time',\n",
       " 'couple week',\n",
       " 'couple year',\n",
       " 'course correct',\n",
       " 'course want',\n",
       " 'course year',\n",
       " 'crazy thing',\n",
       " 'create business',\n",
       " 'create change',\n",
       " 'create company',\n",
       " 'create content',\n",
       " 'create culture',\n",
       " 'create environment',\n",
       " 'create good',\n",
       " 'create great',\n",
       " 'create kind',\n",
       " 'create lot',\n",
       " 'create new',\n",
       " 'create opportunity',\n",
       " 'create product',\n",
       " 'create sense',\n",
       " 'create value',\n",
       " 'creative director',\n",
       " 'creative idea',\n",
       " 'creative people',\n",
       " 'creative process',\n",
       " 'credit card',\n",
       " 'critically important',\n",
       " 'cultural fit',\n",
       " 'culture company',\n",
       " 'culture just',\n",
       " 'culture know',\n",
       " 'culture make',\n",
       " 'culture need',\n",
       " 'culture organization',\n",
       " 'culture people',\n",
       " 'culture really',\n",
       " 'culture thing',\n",
       " 'culture think',\n",
       " 'culture try',\n",
       " 'culture value',\n",
       " 'culture want',\n",
       " 'culture work',\n",
       " 'cup coffee',\n",
       " 'current job',\n",
       " 'customer actually',\n",
       " 'customer ask',\n",
       " 'customer base',\n",
       " 'customer business',\n",
       " 'customer come',\n",
       " 'customer customer',\n",
       " 'customer employee',\n",
       " 'customer experience',\n",
       " 'customer focus',\n",
       " 'customer good',\n",
       " 'customer happy',\n",
       " 'customer just',\n",
       " 'customer know',\n",
       " 'customer look',\n",
       " 'customer make',\n",
       " 'customer mean',\n",
       " 'customer need',\n",
       " 'customer people',\n",
       " 'customer really',\n",
       " 'customer right',\n",
       " 'customer say',\n",
       " 'customer service',\n",
       " 'customer support',\n",
       " 'customer talk',\n",
       " 'customer tell',\n",
       " 'customer think',\n",
       " 'customer time',\n",
       " 'customer use',\n",
       " 'customer want',\n",
       " 'cut edge',\n",
       " 'dad say',\n",
       " 'dad work',\n",
       " 'daily basis',\n",
       " 'datum center',\n",
       " 'datum drive',\n",
       " 'datum make',\n",
       " 'datum point',\n",
       " 'day actually',\n",
       " 'day ask',\n",
       " 'day bad',\n",
       " 'day build',\n",
       " 'day come',\n",
       " 'day company',\n",
       " 'day day',\n",
       " 'day feel',\n",
       " 'day good',\n",
       " 'day hour',\n",
       " 'day important',\n",
       " 'day job',\n",
       " 'day just',\n",
       " 'day know',\n",
       " 'day later',\n",
       " 'day learn',\n",
       " 'day leave',\n",
       " 'day life',\n",
       " 'day long',\n",
       " 'day look',\n",
       " 'day lot',\n",
       " 'day make',\n",
       " 'day need',\n",
       " 'day new',\n",
       " 'day people',\n",
       " 'day probably',\n",
       " 'day really',\n",
       " 'day say',\n",
       " 'day spend',\n",
       " 'day start',\n",
       " 'day talk',\n",
       " 'day tell',\n",
       " 'day thing',\n",
       " 'day think',\n",
       " 'day time',\n",
       " 'day use',\n",
       " 'day walk',\n",
       " 'day want',\n",
       " 'day week',\n",
       " 'day work',\n",
       " 'day year',\n",
       " 'deal customer',\n",
       " 'deal issue',\n",
       " 'deal people',\n",
       " 'deal thing',\n",
       " 'decade ago',\n",
       " ...]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(combined.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = combined.drop(['NAME '], axis = 1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = combined.reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = combined.drop(['text', 'filename'], axis = 1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.to_json('tokensmeta.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
